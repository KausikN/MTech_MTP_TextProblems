{
    "dataset": "wnut_17",
    "model": "amir13_xlm_roberta_base_wnut2017_en",
    "dataset_params": {
        "shuffle": true,
        "shuffle_seed": 0,
        "N": 500,
        "split": "test"
    },
    "eval_params": {
        "device": "cpu",
        "metrics": [
            "seqeval"
        ],
        "other_params": {
            "input_column": "tokens",
            "label_column": "ner_tags"
        }
    },
    "eval": {
        "corporation": {
            "precision": 0.23529411764705882,
            "recall": 0.3333333333333333,
            "f1": 0.27586206896551724,
            "number": 24
        },
        "creative-work": {
            "precision": 0.6363636363636364,
            "recall": 0.2916666666666667,
            "f1": 0.4,
            "number": 48
        },
        "group": {
            "precision": 0.5,
            "recall": 0.16417910447761194,
            "f1": 0.24719101123595505,
            "number": 67
        },
        "location": {
            "precision": 0.6304347826086957,
            "recall": 0.5370370370370371,
            "f1": 0.5800000000000001,
            "number": 54
        },
        "person": {
            "precision": 0.7597402597402597,
            "recall": 0.7090909090909091,
            "f1": 0.7335423197492162,
            "number": 165
        },
        "product": {
            "precision": 0.2777777777777778,
            "recall": 0.10638297872340426,
            "f1": 0.15384615384615385,
            "number": 47
        },
        "overall_precision": 0.6216216216216216,
        "overall_recall": 0.454320987654321,
        "overall_f1": 0.5249643366619116,
        "overall_accuracy": 0.9518766066838046,
        "total_time_in_seconds": 97.91820387800001,
        "samples_per_second": 5.106302813958566,
        "latency_in_seconds": 0.19583640775600003,
        "model_parameter_count": 277463053
    }
}